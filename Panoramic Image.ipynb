{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 \n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "UBIT = 'mgosi'\n",
    "np.random.seed(sum([ord(c) for c in UBIT]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating SIFT Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img1 = cv2.imread('tsucuba_left.png')\n",
    "img2 = cv2.imread('tsucuba_right.png')\n",
    "\n",
    "gray_1= cv2.cvtColor(img1,cv2.COLOR_BGR2GRAY)\n",
    "gray_2= cv2.cvtColor(img2,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "sift = cv2.xfeatures2d.SIFT_create()\n",
    "\n",
    "kp_1, dp_1 = sift.detectAndCompute(gray_1,None)\n",
    "kp_2, dp_2 = sift.detectAndCompute(gray_2,None)\n",
    "\n",
    "img_1=cv2.drawKeypoints(gray_1,kp_1,img1)\n",
    "img_2=cv2.drawKeypoints(gray_2,kp_2,img2)\n",
    "\n",
    "cv2.imwrite('task2_sift1.jpg',img_1)\n",
    "cv2.imwrite('task2_sift2.jpg',img_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Knn Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Using Brute Force Matcher\n",
    "bf = cv2.BFMatcher()\n",
    "#tries to match the closed descriptor to the second image\n",
    "matches = bf.knnMatch(dp_1, dp_2, k= 2)\n",
    "\n",
    "# store all the good_matches matches as per Lowe's ratio test.\n",
    "good_matches = []\n",
    "pts1 = []\n",
    "pts2 = []\n",
    "\n",
    "for m,n in matches:\n",
    "    if m.distance < 0.75*n.distance:\n",
    "        good_matches.append(m)\n",
    "        pts2.append(kp_2[m.trainIdx].pt)         #Gives us the index of the descriptor in the list of train descriptors \n",
    "        pts1.append(kp_1[m.queryIdx].pt)        #Gives us the index of the descriptor in the list of query descriptors \n",
    "\n",
    "img_3 = cv2.drawMatches(img_1,kp_1,img_2,kp_2,good_matches,None,flags=2)\n",
    "cv2.imwrite(\"task2_matches_knn.jpg\",img_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fundamental Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fundamental Matrix :\n",
      "[[-2.12607354e-06 -8.10713687e-05  7.47530309e-02]\n",
      " [ 4.60726414e-05  3.79326900e-05  1.32728554e+00]\n",
      " [-7.52042326e-02 -1.32608913e+00  1.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "pts1 = np.int32(pts1)\n",
    "pts2 = np.int32(pts2)\n",
    "\n",
    "#Selecting 10 random points\n",
    "ran_pts1 = []\n",
    "ran_pts2 = []\n",
    "for i in [np.random.randint(0,len(pts1) -1 ) for x in range(10)] :\n",
    "    ran_pts1.append(pts1[i])\n",
    "    ran_pts2.append(pts2[i])\n",
    "\n",
    "ran_pts1 = np.int32(ran_pts1)\n",
    "ran_pts2 = np.int32(ran_pts2)\n",
    "\n",
    "#print (ran_pts1, ran_pts2)\n",
    "F, mask = cv2.findFundamentalMat(pts1,pts2,cv2.FM_RANSAC)\n",
    "\n",
    "# We select only inlier points\n",
    "pts1 = pts1[mask.ravel()==1]\n",
    "pts2 = pts2[mask.ravel()==1]\n",
    "print (\"Fundamental Matrix :\")\n",
    "print (F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawlines(img1,img2,lines,pts1,pts2):\n",
    "    r,c = img1.shape[:2]\n",
    "    img1 = cv2.cvtColor(img1,cv2.COLOR_GRAY2BGR)\n",
    "    img2 = cv2.cvtColor(img2,cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    for r,pt1,pt2, clr in zip(lines,pts1,pts2, color):\n",
    "        x0,y0 = map(int, [0, -r[2]/r[1] ])\n",
    "        x1,y1 = map(int, [c, -(r[2]+r[0]*c)/r[1] ])\n",
    "        img1 = cv2.line(img1, (x0,y0), (x1,y1), clr,1)\n",
    "        img1 = cv2.circle(img1,tuple(pt1),5,clr,-1)\n",
    "        img2 = cv2.circle(img2,tuple(pt2),5,clr,-1)\n",
    "    return img1,img2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Epipolar Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Taking 10 random \n",
    "color = []\n",
    "for i in range(10):\n",
    "    color.append(tuple(np.random.randint(0,255,3).tolist()))\n",
    "#Find epilines corresponding to points in right image (second image) and\n",
    "# drawing its lines on left image\n",
    "lines1 = cv2.computeCorrespondEpilines(ran_pts2.reshape(-1,1,2), 2,F)\n",
    "lines1 = lines1.reshape(-1,3)\n",
    "img5,img6 = drawlines(gray_1,gray_2,lines1,ran_pts1,ran_pts2)\n",
    "\n",
    "#Find epilines corresponding to points in left image (first image) and\n",
    "# drawing its lines on right image\n",
    "lines2 = cv2.computeCorrespondEpilines(ran_pts1.reshape(-1,1,2), 1,F)\n",
    "lines2 = lines2.reshape(-1,3)\n",
    "img3,img4 = drawlines(gray_2,gray_1,lines2,ran_pts2,ran_pts1)\n",
    "\n",
    "cv2.imwrite(\"task2_epi_right.jpg\",img5)\n",
    "cv2.imwrite(\"task2_epi_left.jpg\",img3)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Disparity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calculating Disparity\n",
    "\n",
    "window_size = 3\n",
    "min_disp = 16\n",
    "num_disp = 144-min_disp\n",
    "#setting the parameters to show disparity\n",
    "stereo = cv2.StereoSGBM_create(minDisparity = min_disp,\n",
    "        numDisparities = num_disp,\n",
    "        uniquenessRatio = 10,\n",
    "        speckleWindowSize = 100,\n",
    "        speckleRange = 32,\n",
    "        disp12MaxDiff = 1,\n",
    "        P1 = 8*3*window_size**2,\n",
    "        P2 = 32*3*window_size**2\n",
    "    )\n",
    "disparity = stereo.compute(gray_1,gray_2).astype(np.float32)/16.0\n",
    "cv2.imwrite('task2_disparity.jpg',disparity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
